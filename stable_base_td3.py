import os
import numpy as np
from controller.environment.multenv_v2 import Multenv2
from stable_baselines3 import TD3
from stable_baselines3.common.callbacks import BaseCallback
from stable_baselines3.common.results_plotter import load_results, ts2xy
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.noise import NormalActionNoise


class SaveOnBestTrainingRewardCallback(BaseCallback):
    """
    Callback for saving a pretrained (the check is done every ``check_freq`` steps)
    based on the training reward (in practice, we recommend using ``EvalCallback``).
    :param check_freq: (int)
    :param log_dir: (str) Path to the folder where the pretrained will be saved.
      It must contains the file created by the ``Monitor`` wrapper.
    :param verbose: (int)
    """
    def __init__(self, check_freq: int, log_dir: str, verbose=1):
        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)
        self.check_freq = check_freq
        self.log_dir = log_dir
        self.save_path = os.path.join(log_dir, 'best_model')
        self.best_mean_reward = -np.inf

    def _init_callback(self) -> None:
        # Create folder if needed
        if self.save_path is not None:
            os.makedirs(self.save_path, exist_ok=True)

    def _on_step(self) -> bool:
        if self.n_calls % self.check_freq == 0:
          # Retrieve training reward
          x, y = ts2xy(load_results(self.log_dir), 'timesteps')
          if len(x) > 0:
              # Mean training reward over the last 100 episodes
              mean_reward = np.mean(y[-100:])
              if self.verbose > 0:
                print(f"Num timesteps: {self.num_timesteps}")
                print(f"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}")

              # New best pretrained, you could save the agent here
              if mean_reward > self.best_mean_reward:
                  self.best_mean_reward = mean_reward
                  # Example for saving best pretrained
                  if self.verbose > 0:
                    print(f"Saving new best pretrained to {self.save_path}.zip")
                  self.model.save(self.save_path)
        return True

log_dir = "stable_pretrained_model/td3_3000_monitor/"
os.makedirs(log_dir, exist_ok=True)
env=Multenv2()
env=Monitor(env,log_dir)
callback = SaveOnBestTrainingRewardCallback(check_freq=100, log_dir=log_dir)
# Create action noise because TD3 and DDPG use a deterministic policy
n_actions = env.action_space.shape[-1]
action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))
# pretrained = TD3("MlpPolicy", env, verbose=0,action_noise=action_noise)
# pretrained.learn(total_timesteps=10000,callback=callback)
# # Save the agent
# del pretrained  # delete trained pretrained to demonstrate loading
model = TD3.load("stable_pretrained_model/td3_3000_monitor/best_model.zip")
obs = env.reset()
epoch=0
total_reward=[]
for i in range(1000):
    action, _states = model.predict(obs, deterministic=True)
    obs, reward, done, info = env.step(action)
    total_reward.append(reward)
    if done:
        print(f"The total reward : {sum(total_reward)}")
        print('io_cost : ', env.io_cost)
        print('action list : ', env.action_list)
        print(f"Average query cost: {sum(env.io_cost) / sum([sql['feature'].frequency for sql in env.w.sql_list])}")
        epoch+=1
        obs = env.reset()
        if  epoch==1:break
env.close()

# from stable_baselines3.common import results_plotter
# #Helper from the library
# results_plotter.plot_results([log_dir], 10000, results_plotter.X_TIMESTEPS, "A2C Controller")


# TD3
# 3000query-steam.csv
# Steps:10000
# The total reward : -9.185087231465758
# io_cost :  [9634388.0, 7059812.0]
# action list :  [[0, 26]]
# Average query cost: 495.2739786987866


# Sample action:  [ 1. 50.]  ,Step: 496
# The total reward : -8.922582310411538
# io_cost :  [33360, 16703.0, 199204.0, 170443.0, 52463.0, 30637.0, 347907.0, 7236069.0]
# action list :  [[-47, 3], [-45, 5], [-43, 7], [-42, 8], [-41, 9], [-40, 10], [-37, 13]]
# Average query cost: 239.91414246298987

# 10000
# # 修改环境后：一旦aciton==1，无论reward好坏，就将自动采取分区方案。（这是不合理的，因为reward本身就是估计的，我们有能力通过reward进行判断）
# The total reward : -0.21611771649942502
# io_cost :  [9414896.0, 18666.0, 30211.0, 37232.0, 37751.0, 43474.0, 11842.0, 46170.0, 27758.0, 61156.0, 6252.0, 11043.0, 8320, 12351.0, 9600, 2560, 5385.0, 1920, 7610.0, 17786.0, 50309.0, 35391.0, 52421.0, 74654.0, 33835.0, 37829.0, 30447.0, 21421.0, 6662.0, 904.0, 5504, 5184, 2052.0, 1600, 2473.0, 3204.0, 6320.0, 8820.0, 30607.0, 50450.0, 25003.0, 61596.0, 42353.0, 19598.0, 42496.0, 28003.0, 6720, 5040, 7349.0, 7632.0, 2272.0, 3548.0, 7790.0, 26914.0, 26441.0, 38800.0, 28532.0, 61482.0, 26079.0, 28210.0, 47217.0, 29408.0, 15670.0, 3947.0, 1677.0, 3552, 12252.0, 3840, 13504.0, 18135.0, 43267.0, 83095.0, 36787.0, 51731.0, 33890.0, 13512.0, 15668.0, 30020.0, 2160, 2886.0, 7200, 3600, 1680, 4348.0, 7182.0, 15423.0, 16182.0, 23002.0, 19973.0, 63453.0, 57061.0, 47300.0, 22573.0, 24303.0, 5003.0, 3120, 4898.0, 6463.0, 4320, 4218.0, 2160, 2400, 5808, 6166.0, 27957.0, 31731.0, 33181.0, 47888.0, 24245.0, 23474.0, 42724.0, 20424.0, 10460.0, 380.0, 12780.0, 2422.0, 4800, 4020.0, 2964.0, 8412.0, 22303.0, 30232.0, 45613.0, 37787.0, 33035.0, 40804.0, 51573.0, 25871.0, 8491.0, 13720.0, 2822.0, 7216.0, 2664.0, 558.0, 15198.0, 18102.0, 36855.0, 38577.0, 53939.0, 28983.0, 26418.0, 23770.0, 28492.0, 7744.0, 7668.0, 8708.0, 18124.0, 14924.0, 1530.0, 3840.0, 24325.0, 24277.0, 46484.0, 38254.0, 38067.0, 41621.0, 31454.0, 38600.0, 15932.0, 24949.0, 5595.0, 2800, 1560.0, 8160, 11393.0, 20487.0, 43607.0, 20018.0, 30766.0, 55484.0, 52721.0, 24233.0, 17340.0, 8164.0, 4120.0, 3401.0, 7692.0, 13681.0, 25767.0, 21869.0, 37791.0, 39825.0, 35505.0, 40400.0, 36050.0, 25965.0, 30120.0, 14447.0, 24970.0, 4966.0, 690.0, 3909.0, 6270.0, 4638.0, 32420.0, 31692.0, 38807.0, 52850.0, 29479.0, 45968.0, 25680.0, 26344.0, 26632.0, 4630.0, 15136.0, 11581.0, 3096.0, 3600, 2880, 795.0, 12116.0, 33426.0, 48418.0, 37765.0, 23492.0, 26708.0, 39066.0, 32694.0, 27584.0, 17538.0, 14296.0, 2400, 2880, 2272, 12136.0, 11977.0, 18192.0, 37244.0, 20536.0, 25855.0, 24538.0, 19235.0, 14084.0, 12240.0, 9193.0, 6544.0, 1760.0, 6173.0, 1503.0, 2208, 5646.0, 7032.0, 6223.0, 16512.0, 25123.0, 40203.0, 31283.0, 26252.0, 14463.0, 11066.0, 12460.0, 3556.0, 8296.0, 2880, 1120, 2064.0, 1821.0, 19831.0, 17031.0, 15163.0, 24643.0, 25192.0, 18165.0, 8479.0, 26350.0, 11270.0, 10865.0, 480, 3392, 2464, 5339.0, 18461.0, 34264.0, 16082.0, 35708.0, 37844.0, 21650.0, 22792.0, 17203.0, 6980.0, 858.0, 3293.0, 2560, 2110.0, 160, 2324.0, 6080, 3648.0, 12739.0, 25182.0, 34144.0, 34825.0, 24111.0, 26082.0, 8396.0, 3964.0, 9361.0, 4192, 4580.0, 2080, 6753.0, 4672, 5849.0, 20761.0, 15342.0, 38971.0, 18993.0, 21035.0, 16254.0, 8809.0, 27558.0, 15518.0, 4800, 8160.0, 1920, 693.0, 3840, 1176.0, 6752, 7504.0, 9448.0, 41124.0, 34590.0, 21120, 17774.0, 23631.0, 17817.0, 13368.0, 6722.0, 4000, 2880, 2720, 1152, 3430.0, 9292.0, 18962.0, 22770.0, 20358.0, 18366.0, 14505.0, 26819.0, 30527.0, 19325.0, 3400.0, 4478.0, 1472, 1548.0, 3200, 7520.0, 11293.0, 18648.0, 24677.0, 15200, 25397.0, 14826.0, 14175.0, 31551.0, 8627.0, 2792.0, 6120.0, 960, 2464, 1600, 3309.0, 4480, 14189.0, 25463.0, 8917.0, 22037.0, 28877.0, 43942.0, 15995.0, 9512.0, 8845.0, 906.0, 7114.0]
# action list :  [[-1, 25], [-24, 26], [-23, 27], [-22, 28], [-21, 29], [-20, 30], [-19, 31], [-18, 32], [-17, 33], [-16, 34], [-15, 35], [-14, 36], [-13, 37], [-12, 38], [-11, 39], [-10, 40], [-6, 44], [-5, 45], [-4, 46], [-3, 47], [-2, 48], [-1, 49], [0, 50], [1, 51], [2, 52], [3, 53], [4, 54], [5, 55], [6, 56], [7, 57], [8, 58], [9, 59], [10, 60], [11, 61], [13, 63], [15, 65], [16, 66], [17, 67], [18, 68], [19, 69], [20, 70], [21, 71], [22, 72], [23, 73], [24, 74], [25, 75], [26, 76], [27, 77], [28, 78], [29, 79], [30, 80], [35, 85], [36, 86], [37, 87], [38, 88], [39, 89], [40, 90], [41, 91], [42, 92], [43, 93], [44, 94], [45, 95], [46, 96], [47, 97], [48, 98], [54, 104], [55, 105], [56, 106], [57, 107], [58, 108], [59, 109], [60, 110], [61, 111], [62, 112], [63, 113], [64, 114], [65, 115], [66, 116], [67, 117], [68, 118], [69, 119], [70, 120], [72, 122], [74, 124], [75, 125], [76, 126], [77, 127], [78, 128], [79, 129], [80, 130], [81, 131], [82, 132], [83, 133], [84, 134], [85, 135], [86, 136], [87, 137], [88, 138], [89, 139], [90, 140], [92, 142], [93, 143], [95, 145], [96, 146], [97, 147], [98, 148], [99, 149], [100, 150], [101, 151], [102, 152], [103, 153], [104, 154], [105, 155], [106, 156], [107, 157], [108, 158], [109, 159], [114, 164], [115, 165], [116, 166], [117, 167], [118, 168], [119, 169], [120, 170], [121, 171], [122, 172], [123, 173], [124, 174], [125, 175], [126, 176], [127, 177], [133, 183], [134, 184], [135, 185], [136, 186], [137, 187], [138, 188], [139, 189], [140, 190], [141, 191], [142, 192], [143, 193], [144, 194], [145, 195], [146, 196], [147, 197], [148, 198], [149, 199], [155, 205], [156, 206], [157, 207], [158, 208], [159, 209], [160, 210], [161, 211], [162, 212], [163, 213], [164, 214], [165, 215], [166, 216], [167, 217], [168, 218], [174, 224], [175, 225], [176, 226], [177, 227], [178, 228], [179, 229], [180, 230], [181, 231], [182, 232], [183, 233], [184, 234], [185, 235], [186, 236], [187, 237], [188, 238], [195, 245], [196, 246], [197, 247], [198, 248], [199, 249], [200, 250], [201, 251], [202, 252], [203, 253], [204, 254], [205, 255], [206, 256], [208, 258], [209, 259], [214, 264], [215, 265], [216, 266], [217, 267], [218, 268], [219, 269], [220, 270], [221, 271], [222, 272], [223, 273], [224, 274], [225, 275], [226, 276], [227, 277], [228, 278], [231, 281], [233, 283], [234, 284], [235, 285], [236, 286], [237, 287], [238, 288], [239, 289], [240, 290], [241, 291], [242, 292], [243, 293], [244, 294], [245, 295], [246, 296], [247, 297], [248, 298], [254, 304], [256, 306], [257, 307], [258, 308], [259, 309], [260, 310], [261, 311], [262, 312], [263, 313], [264, 314], [265, 315], [266, 316], [267, 317], [268, 318], [269, 319], [272, 322], [273, 323], [275, 325], [276, 326], [277, 327], [278, 328], [279, 329], [280, 330], [281, 331], [282, 332], [283, 333], [284, 334], [285, 335], [286, 336], [287, 337], [288, 338], [290, 340], [294, 344], [296, 346], [297, 347], [298, 348], [299, 349], [300, 350], [301, 351], [302, 352], [303, 353], [304, 354], [305, 355], [306, 356], [307, 357], [308, 358], [309, 359], [314, 364], [316, 366], [318, 368], [319, 369], [320, 370], [321, 371], [322, 372], [323, 373], [324, 374], [325, 375], [326, 376], [327, 377], [328, 378], [329, 379], [330, 380], [335, 385], [336, 386], [337, 387], [338, 388], [339, 389], [340, 390], [341, 391], [342, 392], [343, 393], [344, 394], [345, 395], [346, 396], [347, 397], [348, 398], [349, 399], [354, 404], [355, 405], [356, 406], [357, 407], [358, 408], [359, 409], [360, 410], [361, 411], [362, 412], [363, 413], [364, 414], [365, 415], [366, 416], [367, 417], [368, 418], [370, 420], [374, 424], [375, 425], [376, 426], [377, 427], [378, 428], [379, 429], [380, 430], [381, 431], [382, 432], [383, 433], [384, 434], [385, 435], [386, 436], [387, 437], [388, 438], [389, 439], [390, 440], [396, 446], [397, 447], [398, 448], [399, 449], [400, 450], [401, 451], [402, 452], [403, 453], [404, 454], [405, 455], [406, 456], [407, 457], [408, 458], [409, 459], [415, 465], [416, 466], [417, 467], [418, 468], [419, 469], [420, 470], [421, 471], [422, 472], [423, 473], [424, 474], [425, 475], [426, 476], [427, 477], [428, 478], [431, 481], [432, 482], [435, 485], [436, 486], [437, 487], [438, 488], [439, 489], [440, 490], [441, 491], [442, 492], [443, 493], [444, 494], [445, 495], [446, 496]]
# Average query cost: 483.0262556738956